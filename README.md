ğŸ“Œ Desafio TÃ©cnico - Comparador de LLMs
ğŸ¯ Objetivo
Desenvolver uma soluÃ§Ã£o que acesse pelo menos trÃªs Modelos de Linguagem de Grande Escala (LLMs) diferentes, gere respostas para uma mesma pergunta e realize uma anÃ¡lise comparativa da qualidade das respostas.

ğŸ› ï¸ Tecnologias Utilizadas
Frontend: Next.js (React)
Backend: Express.js (Node.js)
Linguagem: TypeScript
APIs Utilizadas:
Gemini (Google Generative AI)
Mistral (Mistral AI)
OpenRouter (Acesso a mÃºltiplos modelos)
ğŸš€ ConfiguraÃ§Ã£o do Projeto
ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias
bash
Copiar
Editar
# No diretÃ³rio do backend e frontend, execute:
npm install
â–¶ï¸ ExecuÃ§Ã£o do Projeto
ğŸ”¹ Backend
bash
Copiar
Editar
# Iniciar o servidor backend
npm run dev
Por padrÃ£o, o backend rodarÃ¡ em http://localhost:8080/api/all.

ğŸ”¹ Frontend
bash
Copiar
Editar
# Iniciar o frontend
npm run dev
O frontend serÃ¡ acessÃ­vel em http://localhost:3000.

ğŸ§ª ExecuÃ§Ã£o de Testes
bash
Copiar
Editar
# Rodar testes unitÃ¡rios
npm run test
ğŸ”§ ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente
Para executar o projeto corretamente, Ã© necessÃ¡rio criar um arquivo .env no backend e preencher com as chaves de API dos provedores:

env
Copiar
Editar
GEMINI_API_KEY='SUA_CHAVE_AQUI'
MISTRAL_API_KEY='SUA_CHAVE_AQUI'
OPENROUTER_API_KEY='SUA_CHAVE_AQUI'
Onde obter as chaves:

Gemini (Google AI): Obter chave
Mistral AI: Obter chave
OpenRouter (acesso a mÃºltiplos modelos): Obter chave


ğŸ“Š ComparaÃ§Ã£o das Respostas e AvaliaÃ§Ã£o
1ï¸âƒ£ Recebimento do Prompt
ğŸ“Œ O usuÃ¡rio insere um prompt no frontend.

2ï¸âƒ£ GeraÃ§Ã£o das Respostas
ğŸ“Œ O backend chama os serviÃ§os GeminiService, MistralService e OpenRouterService.

3ï¸âƒ£ AutoavaliaÃ§Ã£o Assistida por IA
ğŸ“Œ As respostas geradas sÃ£o enviadas para os prÃ³prios modelos avaliarem segundo critÃ©rios como clareza, precisÃ£o, criatividade e gramÃ¡tica.

4ï¸âƒ£ CÃ¡lculo da Melhor Resposta
ğŸ“Œ A melhor resposta Ã© definida com base na mÃ©dia das notas e exibida no frontend.

ğŸ† Ranking dos Modelos
PosiÃ§Ã£o	Modelo	Nota Final
ğŸ¥‡ 1Âº	Mistral	8.67
ğŸ¥ˆ 2Âº	OpenRouter	8.06
ğŸ¥‰ 3Âº	Gemini	8.00
ğŸ“Œ ConclusÃ£o
ğŸ“Œ Mistral teve o melhor desempenho geral, combinando clareza, precisÃ£o e criatividade.
ğŸ“Œ OpenRouter apresentou boas respostas, mas com desempenho irregular dependendo do modelo usado.
ğŸ“Œ Gemini se destacou na gramÃ¡tica e estrutura das respostas, mas perdeu pontos em precisÃ£o.

ğŸ“© Contato
Caso tenha alguma dÃºvida sobre a implementaÃ§Ã£o, fique Ã  vontade para entrar em contato! ğŸš€

Dev RodrigoSousaFintes
